{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3993581a",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n",
    "\n",
    "What is K-Means?\n",
    "K-Means is an iterative, centroid-based partitioning algorithm for unsupervised learning that:\n",
    "\n",
    "Partitions n observations into k clusters\n",
    "\n",
    "Minimizes within-cluster variance (inertia)\n",
    "\n",
    "Assumes spherical, equally-sized clusters with similar densities\n",
    "\n",
    "```bash\n",
    "K-Means = Partition + Minimize Distance\n",
    "\n",
    "Unsupervised learning - no labels needed\n",
    "\n",
    "Centroid-based - each cluster has a center point\n",
    "\n",
    "Distance minimization - points assigned to nearest centroid\n",
    "\n",
    "Iterative refinement - repeats until convergence\n",
    "```\n",
    "Objective Function (Inertia/WCSS):\n",
    "``` Inertia = Σ Σ ||x - μ_k||² ```\n",
    "\n",
    "where:\n",
    "\n",
    "x = data point in cluster k\n",
    "\n",
    "μ_k = centroid of cluster k\n",
    "\n",
    "Goal: Minimize this value\n",
    "\n",
    "``` Time: O(n × k × d × i)```\n",
    "```Space: O(n × k + k × d)```\n",
    "\n",
    "Clustering = grouping similar data points\n",
    "No labels given\n",
    "Algorithm finds structure by itself\n",
    "That’s unsupervised learning\n",
    "\n",
    "\n",
    "K-Means = partition data into K clusters using distance\n",
    "\n",
    "K = number of clusters (chosen by us)\n",
    "\n",
    "Means = centroid = average of points\n",
    "\n",
    "Each cluster is represented by its mean\n",
    "\n",
    "params:\n",
    "KMeans(\n",
    "    n_clusters=8,           # Most important: choose carefully\n",
    "    init='k-means++',       # Smart initialization\n",
    "    n_init=10,              # Run 10 times, keep best\n",
    "    max_iter=300,           # Maximum iterations\n",
    "    tol=1e-4,               # Convergence tolerance\n",
    "    random_state=42,        # Reproducibility\n",
    "    algorithm='auto'        # 'elkan' faster for dense data\n",
    ")\n",
    "\n",
    "\n",
    "Random init → bad clusters\n",
    "K-Means++ → smart initialization\n",
    "\n",
    "How?\n",
    "\n",
    "First centroid randomly\n",
    "\n",
    "Next centroid chosen far from existing ones\n",
    "\n",
    " Faster convergence\n",
    " Better clusters\n",
    "\n",
    "When K-Means FAILS (Very Important)\n",
    "\n",
    " Non-spherical clusters\n",
    " Different cluster sizes\n",
    " Different densities\n",
    " Sensitive to outliers\n",
    " Need to choose K manually\n",
    "\n",
    " Example where K-Means fails:\n",
    "Moon-shaped data\n",
    "\n",
    "K-Means is distance-based\n",
    "\n",
    " Features must be scaled\n",
    "\n",
    "Evaluation Metrics\n",
    "\n",
    "Since no labels:\n",
    "\n",
    "Inertia (WCSS)\n",
    "\n",
    "Silhouette Score\n",
    "\n",
    "Davies-Bouldin Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7178d31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids: [[1, 2], [10, 2]]\n",
      "Clusters: [[[1, 2], [1, 4], [1, 0]], [[10, 2], [10, 4], [10, 0]]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "def euclidean_distance(p1, p2):\n",
    "    return math.sqrt(sum((a - b) ** 2 for a, b in zip(p1, p2)))\n",
    "def assign_clusters(X, centroids):\n",
    "    clusters = [[] for _ in centroids]\n",
    "    \n",
    "    for point in X:\n",
    "        distances = [euclidean_distance(point, c) for c in centroids]\n",
    "        cluster_index = distances.index(min(distances))\n",
    "        clusters[cluster_index].append(point)\n",
    "    \n",
    "    return clusters\n",
    "def update_centroids(clusters):\n",
    "    new_centroids = []\n",
    "    \n",
    "    for cluster in clusters:\n",
    "        centroid = [\n",
    "            sum(dim) / len(cluster)\n",
    "            for dim in zip(*cluster)\n",
    "        ]\n",
    "        new_centroids.append(centroid)\n",
    "    \n",
    "    return new_centroids\n",
    "def kmeans(X, k, max_iters=100):\n",
    "    centroids = random.sample(X, k)\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        clusters = assign_clusters(X, centroids)\n",
    "        new_centroids = update_centroids(clusters)\n",
    "\n",
    "        if new_centroids == centroids:\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    return clusters, centroids\n",
    "X = [\n",
    "    [1, 2], [1, 4], [1, 0],\n",
    "    [10, 2], [10, 4], [10, 0]\n",
    "]\n",
    "\n",
    "clusters, centroids = kmeans(X, k=2)\n",
    "\n",
    "print(\"Centroids:\", centroids)\n",
    "print(\"Clusters:\", clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fae7b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [0 1 0 1 1 0]\n",
      "Centroids: [[-0.33333333 -0.81649658]\n",
      " [ 0.33333333  0.81649658]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X = np.array([\n",
    "    [1, 2], [1, 4], [1, 0],\n",
    "    [10, 2], [10, 4], [10, 0]\n",
    "])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans = KMeans(\n",
    "    n_clusters=2,\n",
    "    init='k-means++',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "kmeans.fit(X_scaled)\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "print(\"Labels:\", labels)\n",
    "print(\"Centroids:\", centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961ce336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.15910418698883563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = silhouette_score(X_scaled, labels)\n",
    "print(\"Silhouette Score:\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c61c0b",
   "metadata": {},
   "source": [
    "WHY use K-Means?\n",
    "To find structure in unlabeled data\n",
    "\n",
    "When:\n",
    "\n",
    "You don’t have labels\n",
    "\n",
    "You still want to group similar data\n",
    "\n",
    "Example\n",
    "You have customers, but no “type” column\n",
    "→ K-Means discovers customer segments automatically\n",
    "\n",
    "Simple, fast, and scalable \n",
    "\n",
    "Why companies love it:\n",
    "\n",
    "Easy to understand\n",
    "\n",
    "Very fast even for large datasets\n",
    "\n",
    "Works well in high dimensions (with scaling)\n",
    "\n",
    "Used in:\n",
    "\n",
    "Industry\n",
    "\n",
    "Interviews\n",
    "\n",
    "Baseline clustering\n",
    "\n",
    "Clear objective function\n",
    "\n",
    "K-Means minimizes within-cluster distance (WCSS)\n",
    "\n",
    "This makes it:\n",
    "\n",
    "Mathematically clean\n",
    "\n",
    "Easy to optimize\n",
    "\n",
    "Easy to explain\n",
    "\n",
    "Easy to interpret results\n",
    "\n",
    "Output is:\n",
    "\n",
    "Cluster labels\n",
    "\n",
    "Centroids (means)\n",
    "\n",
    "Centroid = “average representative” of group\n",
    "\n",
    "Good baseline model\n",
    "\n",
    "Before trying complex clustering:\n",
    "\n",
    "Try K-Means first\n",
    "\n",
    "If it works → great\n",
    "\n",
    "If not → move to DBSCAN / Hierarchical\n",
    "\n",
    "WHEN to use K-Means?\n",
    "\n",
    "Use K-Means ONLY if these conditions are mostly true \n",
    "\n",
    "Data is numerical\n",
    "\n",
    "K-Means uses distance.\n",
    "\n",
    "Height, weight, income\n",
    "Color, category, text (without encoding)\n",
    "\n",
    "Clusters are roughly spherical\n",
    "\n",
    "K-Means assumes:\n",
    "\n",
    "Round-shaped clusters\n",
    "\n",
    "Equal spread\n",
    "\n",
    "Works well when clusters look like “balls”\n",
    "\n",
    "Similar cluster sizes\n",
    "\n",
    "If one cluster is huge and one is tiny →  bad\n",
    "\n",
    "ou know (or can estimate) K\n",
    "\n",
    "You can:\n",
    "\n",
    "Use Elbow Method\n",
    "\n",
    "Use Silhouette Score\n",
    "\n",
    "Use domain knowledge\n",
    "\n",
    "Few outliers\n",
    "\n",
    "Outliers pull centroids badly\n",
    "\n",
    "Always check:\n",
    "\n",
    "Boxplot\n",
    "\n",
    "Scatter plot\n",
    "\n",
    "WHEN NOT to use K-Means \n",
    "Non-spherical clusters\n",
    "\n",
    "Example:\n",
    "\n",
    "Moon shape\n",
    "\n",
    "Spiral shape\n",
    "\n",
    "Use DBSCAN\n",
    "\n",
    "Different densities\n",
    "\n",
    "One cluster dense, another sparse\n",
    "\n",
    "K-Means fails\n",
    "\n",
    "Categorical data only\n",
    "\n",
    "Distance doesn’t make sense\n",
    "\n",
    "Use:\n",
    "\n",
    "K-Modes\n",
    "\n",
    "Hierarchical clustering\n",
    "\n",
    "Many outliers\n",
    "\n",
    "Centroid shifts incorrectly\n",
    "Clean data or use DBSCAN\n",
    "\n",
    "\n",
    "Customer Segmentation\n",
    "Features: age, income, spending_score\n",
    "Why K-Means?\n",
    "✔ Numeric\n",
    "✔ Want segments\n",
    "✔ Fast\n",
    "\n",
    "Image Compression\n",
    "Sales, visits, revenue\n",
    "\n",
    "Document Clustering (after TF-IDF)\n",
    "Vectors are numeric → K-Means works\n",
    "\n",
    "Why do you use K-Means?\n",
    "K-Means is used to cluster unlabeled numerical data by minimizing within-cluster variance. It is fast, simple, scalable, and works well when clusters are spherical and of similar size.\n",
    "\n",
    "When do you use K-Means?\n",
    "I use K-Means when the data is numerical, scaled, has few outliers, and when the number of clusters can be estimated using methods like the elbow or silhouette score.\n",
    "\n",
    "K-Means = fast + numeric + spherical + known K\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
