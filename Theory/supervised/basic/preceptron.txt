1. What is a Perceptron?

A Perceptron is the simplest type of neural network.
It is mostly used for:

 Small datasets
 Binary classification
 Linearly separable patterns (very important!)

It is one of the earliest supervised ML algorithms for classification.


2. Why Perceptron is NOT used much today?

Because:

It only works when the data is linearly separable

It cannot solve complex problems (like XOR)

Many better binary classifiers exist now:

Logistic Regression

SVM

Decision Trees

Neural Networks (MLP)

3. When do we use Perceptron?

Use it when:

 Dataset is small
 Problem is binary classification (0/1)
 Data is linearly separable
 You want a simple and fast model

4. Types of Perceptron

There are two types based on layers:

A) Single-Layer Perceptron (SLP)

 Has no hidden layer
 Only input → output
 Only for linearly separable data



B) Multi-Layer Perceptron (MLP)

 Has one or more hidden layers
 Can model non-linear patterns
 Uses activation functions (ReLU, sigmoid, tanh)

This is what people usually call a Neural Network.

5. Perceptron Learning Rule (Weight Update)

w = w + η * (y_true – y_pred) * x
b = b + η * (y_true – y_pred)

Where:

η = learning rate

y_true = actual label

y_pred = predicted label

This is called the Perceptron Rule.


Perceptron is a simple supervised ML algorithm used mainly for binary classification on small, linearly separable datasets. It can be single-layer (no hidden layer) or multi-layer (MLP). The perceptron updates its weights using a simple rule based on prediction error. Although not commonly used in modern ML due to limitations, it is fundamental for understanding neural networks.