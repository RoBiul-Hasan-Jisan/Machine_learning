{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dec81217",
   "metadata": {},
   "source": [
    "# Model Evaluation Metrics\n",
    "\n",
    "Choosing the right metric is as important as choosing the right model. The metric defines what the model tries to optimize.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Regression Metrics (Continuous Targets)\n",
    "\n",
    "### Error-based Metrics\n",
    "These measure the distance between predicted values ($\\hat{y}$) and actual values ($y$).\n",
    "\n",
    "**1. MAE (Mean Absolute Error)**\n",
    "The average of absolute differences.\n",
    "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
    "* **Pros:** Robust to outliers; easily interpretable in original units.\n",
    "* **Cons:** Non-differentiable at zero (harder for Gradient Descent).\n",
    "\n",
    "**2. MSE (Mean Squared Error)**\n",
    "The average of squared differences.\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "* **Pros:** Differentiable; useful for optimization.\n",
    "* **Cons:** Penalizes larger errors heavily (sensitive to outliers).\n",
    "\n",
    "**3. RMSE (Root Mean Squared Error)**\n",
    "The square root of MSE.\n",
    "$$RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n",
    "* **Pros:** Same units as the target variable (e.g., dollars, meters).\n",
    "* **Cons:** Highly sensitive to outliers.\n",
    "\n",
    "**4. RMSLE (Root Mean Squared Logarithmic Error)**\n",
    "Takes the log of predictions and actuals before calculating error.\n",
    "$$RMSLE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (\\log(\\hat{y}_i + 1) - \\log(y_i + 1))^2}$$\n",
    "* **Pros:** Penalizes underestimates more than overestimates; good for exponential growth data.\n",
    "\n",
    "---\n",
    "\n",
    "### Percentage Error Metrics\n",
    "Useful for explaining error to non-technical stakeholders (e.g., \"We are off by 5%\").\n",
    "\n",
    "**1. MAPE (Mean Absolute Percentage Error)**\n",
    "$$MAPE = \\frac{100\\%}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right|$$\n",
    "* **Cons:** Undefined if $y=0$; punishes negative errors differently than positive ones.\n",
    "\n",
    "**2. sMAPE (Symmetric MAPE)**\n",
    "Bounds the error between 0% and 200%.\n",
    "$$sMAPE = \\frac{200\\%}{n} \\sum_{i=1}^{n} \\frac{|\\hat{y}_i - y_i|}{|y_i| + |\\hat{y}_i|}$$\n",
    "\n",
    "---\n",
    "\n",
    "### Goodness-of-fit Metrics\n",
    "\n",
    "**1. $R^2$ (Coefficient of Determination)**\n",
    "Proportion of variance in the dependent variable explained by the model.\n",
    "$$R^2 = 1 - \\frac{SS_{residual}}{SS_{total}} = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2}$$\n",
    "* **Range:** $(-\\infty, 1]$. An $R^2$ of 1 is perfect; 0 is baseline (guessing the mean).\n",
    "\n",
    "**2. Adjusted $R^2$**\n",
    "Penalizes adding useless features. (Standard $R^2$ always increases as you add features).\n",
    "$$R^2_{adj} = 1 - (1-R^2) \\frac{n-1}{n-p-1}$$\n",
    "* $n$: Number of samples.\n",
    "* $p$: Number of predictors/features.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Classification Metrics (Categorical Targets)\n",
    "\n",
    "### The Confusion Matrix Components\n",
    "\n",
    "\n",
    "* **TP:** True Positive (Correctly predicted Yes)\n",
    "* **TN:** True Negative (Correctly predicted No)\n",
    "* **FP:** False Positive (Type I Error)\n",
    "* **FN:** False Negative (Type II Error)\n",
    "\n",
    "### Core Metrics\n",
    "\n",
    "**1. Precision**\n",
    "Accuracy of positive predictions. \"Of all the ones I labeled Positive, how many actually were?\"\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "**2. Recall (Sensitivity)**\n",
    "Coverage of actual positives. \"Of all the real Positives, how many did I find?\"\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "**3. F1-Score**\n",
    "The harmonic mean of Precision and Recall. Use this when you need a balance between the two.\n",
    "$$F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$$\n",
    "\n",
    "**4. Specificity**\n",
    "Coverage of actual negatives. \"How good are we at avoiding false alarms?\"\n",
    "$$Specificity = \\frac{TN}{TN + FP}$$\n",
    "\n",
    "---\n",
    "\n",
    "### Threshold-Independent Metrics\n",
    "\n",
    "**1. ROC-AUC (Area Under Receiver Operating Characteristic)**\n",
    "* Plots **TPR (Recall)** vs **FPR ($1 - Specificity$)**.\n",
    "* **Use:** General measure of ranking performance. $0.5$ is random, $1.0$ is perfect.\n",
    "\n",
    "**2. PR-AUC (Area Under Precision-Recall Curve)**\n",
    "* **Use:** Much better than ROC-AUC for **highly imbalanced datasets** (e.g., Fraud Detection).\n",
    "\n",
    "---\n",
    "\n",
    "### Probabilistic & Advanced Metrics\n",
    "\n",
    "**1. Log Loss (Binary Cross-Entropy)**\n",
    "Penalizes confident wrong predictions.\n",
    "$$LogLoss = -\\frac{1}{n} \\sum_{i=1}^{n} [y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i)]$$\n",
    "\n",
    "**2. Matthews Correlation Coefficient (MCC)**\n",
    "A balanced measure even with class imbalance. Range $[-1, 1]$.\n",
    "$$MCC = \\frac{TP \\times TN - FP \\times FN}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}$$\n",
    "\n",
    "---\n",
    "\n",
    "## Summary: When to Use Which?\n",
    "\n",
    "| Scenario | Recommended Metric |\n",
    "| :--- | :--- |\n",
    "| **Regression (Standard)** | **RMSE** (Interpretable), **$R^2$** (Fit quality) |\n",
    "| **Regression (Outliers)** | **MAE** (Robust) |\n",
    "| **Regression (Business)** | **MAPE** (Percentage error is easy to explain) |\n",
    "| **Classification (Balanced)** | **Accuracy**, **F1-Score** |\n",
    "| **Classification (Imbalanced)** | **PR-AUC**, **F1-Score**, **MCC** |\n",
    "| **Minimize False Alarms** | **Precision** (e.g., Spam Detection) |\n",
    "| **Minimize Missed Cases** | **Recall** (e.g., Cancer Diagnosis) |\n",
    "| **Probabilistic Calibration** | **Log Loss**, **Brier Score** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb36d9f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
