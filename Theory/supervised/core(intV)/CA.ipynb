{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3334421a",
   "metadata": {},
   "source": [
    "Definition: The simplest type of binary linear classifier; single-layer neural network.\n",
    "\n",
    "Key Idea: Finds a linear decision boundary by updating weights using misclassified samples.\n",
    "\n",
    "Update Rule:  w=w+η(y−y^)x\n",
    "\n",
    "Pros: Simple, fast, works for linearly separable data.\n",
    "\n",
    "Cons: Cannot handle non-linear data, sensitive to learning rate.\n",
    "\n",
    "When to Use: Binary classification, small/linearly separable datasets.\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "eta0 → learning rate\n",
    "\n",
    "max_iter → maximum iterations\n",
    "\n",
    "fit_intercept → add bias term\n",
    "\n",
    "Adaline / Madaline\n",
    "\n",
    "Definition: Adaline = Adaptive Linear Neuron; Madaline = Multiple Adaline units.\n",
    "\n",
    "Key Idea: Uses continuous activation (linear output) and MSE loss to update weights.\n",
    "\n",
    "Pros: Uses gradient descent → smoother convergence than perceptron.\n",
    "\n",
    "Cons: Only linear decision boundary; Madaline more complex.\n",
    "\n",
    "When to Use: Linearly separable regression/classification problems.\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "learning_rate\n",
    "\n",
    "epochs / max_iter\n",
    "\n",
    "Nearest Centroid Classifier\n",
    "\n",
    "Definition: Distance-based classifier; assigns sample to class with closest centroid.\n",
    "\n",
    "Key Idea: Computes mean feature vector for each class.\n",
    "\n",
    "Pros: Simple, fast, interpretable. Works for well-separated clusters.\n",
    "\n",
    "Cons: Sensitive to outliers, poor performance on overlapping classes.\n",
    "\n",
    "When to Use: High-dimensional data, quick baseline model, linearly separable clusters.\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "metric → distance metric (Euclidean, Manhattan)\n",
    "\n",
    "shrink_threshold → for robustness to noise\n",
    "\n",
    "Ridge Classifier\n",
    "\n",
    "Definition: Linear classifier using Ridge regression; converts labels to {-1,1} and fits linear model.\n",
    "\n",
    "Key Idea: L2 regularization minimizes overfitting.\n",
    "\n",
    "Pros: Works well for high-dimensional data, reduces variance.\n",
    "\n",
    "Cons: Only linear decision boundary.\n",
    "\n",
    "When to Use: High-dimensional data, text classification, regularization needed.\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "alpha → regularization strength\n",
    "\n",
    "fit_intercept → include bias term\n",
    "\n",
    "Passive Aggressive Classifier\n",
    "\n",
    "Definition: Online learning algorithm; updates weights only when misclassification occurs.\n",
    "\n",
    "Key Idea: Passive if correctly classified, aggressive if misclassified → updates weights minimally to fix error.\n",
    "\n",
    "Pros: Good for large-scale online learning, fast.\n",
    "\n",
    "Cons: Sensitive to outliers; may oscillate on noisy data.\n",
    "\n",
    "When to Use: Online/streaming data, large datasets.\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "C → regularization parameter\n",
    "\n",
    "loss → hinge, squared_hinge\n",
    "\n",
    "max_iter\n",
    "\n",
    "SGD Classifier / Regressor\n",
    "\n",
    "Definition: Stochastic Gradient Descent (SGD) algorithm for linear models; supports classification & regression.\n",
    "\n",
    "Key Idea: Updates weights incrementally per sample using gradient of the loss.\n",
    "\n",
    "Pros: Very fast on large datasets, supports online learning, flexible (can implement SVM, logistic regression, etc.).\n",
    "\n",
    "Cons: Needs careful tuning of learning rate, sensitive to feature scaling.\n",
    "\n",
    "When to Use: Very large datasets, online learning, sparse data.\n",
    "\n",
    "Key Parameters:\n",
    "\n",
    "loss → hinge, log, squared_loss, epsilon_insensitive\n",
    "\n",
    "penalty → l2, l1, elasticnet\n",
    "\n",
    "alpha → regularization strength\n",
    "\n",
    "learning_rate → constant, optimal, adaptive\n",
    "\n",
    "max_iter → epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf27586",
   "metadata": {},
   "source": [
    "| Classifier                 | Type            | Pros                                       | Cons                          | Use Case                                   |\n",
    "| -------------------------- | --------------- | ------------------------------------------ | ----------------------------- | ------------------------------------------ |\n",
    "| Perceptron                 | Linear          | Simple, fast                               | Only linearly separable       | Small binary classification                |\n",
    "| Adaline / Madaline         | Linear          | Smooth convergence                         | Linear only, Madaline complex | Regression/classification                  |\n",
    "| Nearest Centroid           | Distance-based  | Fast, interpretable                        | Sensitive to outliers         | Well-separated clusters, baseline          |\n",
    "| Ridge Classifier           | Linear + L2     | Handles high-dim data, reduces overfitting | Linear only                   | Text classification, high-dimensional data |\n",
    "| Passive Aggressive         | Online          | Fast, online learning                      | Sensitive to noise            | Streaming/large datasets                   |\n",
    "| SGD Classifier / Regressor | Online / Linear | Fast, scalable, flexible                   | Needs tuning, feature scaling | Large/streaming datasets                   |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
