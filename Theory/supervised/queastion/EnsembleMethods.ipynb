{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8918fbf",
   "metadata": {},
   "source": [
    "AdaBoost \n",
    "\n",
    "What is AdaBoost, and how does it differ from gradient boosting?\n",
    "\n",
    "Who invented AdaBoost and when? (Freund & Schapire, 1997)\n",
    "\n",
    "Explain the \"adaptive\" part - how does it adaptively weight samples?\n",
    "\n",
    "\n",
    "Write the AdaBoost algorithm pseudocode for binary classification.\n",
    "\n",
    "What are sample weights and how are they updated?\n",
    "\n",
    "How are weak learners combined? (Weighted majority voting)\n",
    "\n",
    "What is the classifier weight α_t and how is it calculated?\n",
    "\n",
    "\n",
    "Derive the formula for classifier weight: α_t = ½ ln((1-ε_t)/ε_t)\n",
    "\n",
    "How are sample weights updated: w_i^{(t+1)} = w_i^{(t)} exp(-α_t y_i h_t(x_i))\n",
    "\n",
    "Explain the exponential loss function: L(y, F(x)) = exp(-yF(x))\n",
    "\n",
    "Show that AdaBoost minimizes exponential loss via stagewise additive modeling.\n",
    "\n",
    "\n",
    "Weak learners: Typically decision stumps (depth-1 trees)\n",
    "\n",
    "Error rate ε_t: Weighted error of weak learner\n",
    "\n",
    "D_t: Distribution over training samples\n",
    "\n",
    "Final classifier: H(x) = sign(∑ α_t h_t(x))\n",
    "\n",
    "Implementation Variants\n",
    "AdaBoost.M1: Original algorithm for binary classification\n",
    "\n",
    "AdaBoost.M2: Extension for multi-class\n",
    "\n",
    "SAMME and SAMME.R (scikit-learn implementations)\n",
    "\n",
    "Real AdaBoost: Using confidence-rated predictions\n",
    "\n",
    "Theoretical Properties\n",
    "Why does AdaBoost focus on \"hard\" examples?\n",
    "\n",
    "What is the margin theory for AdaBoost?\n",
    "\n",
    "How does AdaBoost relate to forward stagewise additive modeling?\n",
    "\n",
    "What is the training error bound? (Decreases exponentially)\n",
    "\n",
    "Advantages & Limitations\n",
    "Advantages:\n",
    "\n",
    "Simple to implement\n",
    "\n",
    "Less prone to overfitting than some algorithms\n",
    "\n",
    "Feature selection capability\n",
    "\n",
    "No need for extensive parameter tuning\n",
    "\n",
    "Limitations:\n",
    "\n",
    "Sensitive to noisy data and outliers\n",
    "\n",
    "Weak learner performance requirement (ε_t < 0.5)\n",
    "\n",
    "Can be slow with many weak learners\n",
    "\n",
    "Less popular than gradient boosting today\n",
    "\n",
    "How to choose the number of estimators in AdaBoost?\n",
    "\n",
    "What happens if a weak learner has error > 0.5?\n",
    "\n",
    "How does AdaBoost handle multi-class problems?\n",
    "\n",
    "Compare AdaBoost vs. Random Forest vs. Gradient Boosting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c449cc",
   "metadata": {},
   "source": [
    "Voting Classifiers\n",
    "\n",
    "What is a voting classifier/regressor?\n",
    "\n",
    "Explain hard voting vs. soft voting\n",
    "\n",
    "What is the wisdom of crowds principle in ensemble learning?\n",
    "\n",
    "Types of Voting\n",
    "Hard Voting (Majority Voting):\n",
    "\n",
    "Final prediction = mode of individual predictions\n",
    "\n",
    "For classification only\n",
    "\n",
    "Simple but effective\n",
    "\n",
    "Soft Voting (Weighted Averaging):\n",
    "\n",
    "Final prediction = weighted average of probability estimates\n",
    "\n",
    "Requires classifiers to output probabilities\n",
    "\n",
    "Often performs better than hard voting\n",
    "\n",
    "Weighted Voting:\n",
    "\n",
    "Assign different weights to different models\n",
    "\n",
    "How to determine optimal weights?\n",
    "\n",
    "Algorithm & Implementation\n",
    "How to implement voting from scratch?\n",
    "\n",
    "scikit-learn: VotingClassifier and VotingRegressor\n",
    "\n",
    "How to choose diverse base models? (Heterogeneous ensembles)\n",
    "\n",
    "Theoretical Basis\n",
    "Condorcet's Jury Theorem: Conditions for majority voting superiority\n",
    "\n",
    "No Free Lunch Theorem: Need for diverse models\n",
    "\n",
    "Error reduction through averaging\n",
    "\n",
    "Advantages & Use Cases\n",
    "Advantages:\n",
    "\n",
    "Simple to implement and understand\n",
    "\n",
    "Can combine different types of models\n",
    "\n",
    "Often improves over single models\n",
    "\n",
    "Parallelizable (models trained independently)\n",
    "\n",
    "Use Cases:\n",
    "\n",
    "Combining fundamentally different algorithms\n",
    "\n",
    "When computational resources allow multiple models\n",
    "\n",
    "Competitions where blending helps\n",
    "\n",
    "Common Combinations\n",
    "Logistic Regression + Random Forest + SVM\n",
    "\n",
    "Linear models + tree-based models + neural networks\n",
    "\n",
    "Different preprocessing pipelines with same algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7cb9b",
   "metadata": {},
   "source": [
    "Stacking Algorithm\n",
    "Split training data into K folds\n",
    "\n",
    "Train base models on K-1 folds, predict on holdout fold\n",
    "\n",
    "Repeat for all folds to get out-of-fold predictions\n",
    "\n",
    "Train meta-model on out-of-fold predictions\n",
    "\n",
    "Retrain base models on full training data\n",
    "\n",
    "Key Components\n",
    "Base learners: Diverse models (heterogeneous stacking)\n",
    "\n",
    "Meta-learner: Typically simple model (linear regression, logistic regression)\n",
    "\n",
    "Out-of-Fold (OOF) predictions: Prevent data leakage\n",
    "\n",
    "Stacking layers: Can have multiple levels (deep stacking)\n",
    "\n",
    "Implementation Details\n",
    "How to prevent target leakage in stacking?\n",
    "\n",
    "What are blending vs. stacking? (Blending uses holdout set)\n",
    "\n",
    "How to handle multi-class problems in stacking?\n",
    "\n",
    "Should base models be correlated or uncorrelated?\n",
    "\n",
    "Variants of Stacking\n",
    "Simple stacking: One meta-model\n",
    "\n",
    "Multi-level stacking: Multiple stacking layers\n",
    "\n",
    "Feature-weighted linear stacking: Learn feature importance\n",
    "\n",
    "Bayesian stacking: Bayesian model averaging\n",
    "\n",
    "Meta-Learner Choices\n",
    "Linear models: Linear regression, logistic regression\n",
    "\n",
    "Tree-based: LightGBM, XGBoost (risk of overfitting)\n",
    "\n",
    "Neural networks: Can capture complex interactions\n",
    "\n",
    "Ridge regression: Good default choice\n",
    "\n",
    "Advantages & Challenges\n",
    "Advantages:\n",
    "\n",
    "Can capture strengths of different models\n",
    "\n",
    "Often highest performance in competitions\n",
    "\n",
    "Flexible framework\n",
    "\n",
    "Challenges:\n",
    "\n",
    "Complex to implement correctly\n",
    "\n",
    "Risk of overfitting\n",
    "\n",
    "Computationally expensive\n",
    "\n",
    "Hard to interpre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7efa9",
   "metadata": {},
   "source": [
    "When to Use Which?\n",
    "\n",
    "Voting: Quick improvement over single models\n",
    "\n",
    "Bagging (RF): Reduce variance, parallel training needed\n",
    "\n",
    "Boosting: Maximize accuracy, handle bias\n",
    "\n",
    "Stacking: Competition settings, maximize performance\n",
    "\n",
    "Blending: Simpler alternative to stacking\n",
    "\n",
    "Performance Considerations\n",
    "Diversity: Essential for all ensemble methods\n",
    "\n",
    "Correlation: Uncorrelated errors improve ensembles\n",
    "\n",
    "Computational cost: Stacking > Boosting > Bagging > Voting\n",
    "\n",
    "Interpretability: Voting > Bagging > Boosting > Stacking\n",
    "\n",
    "\n",
    "Model Diversity\n",
    "Why is diversity important in ensembles?\n",
    "\n",
    "How to measure model diversity? (Q-statistic, correlation, disagreement)\n",
    "\n",
    "Techniques to increase diversity:\n",
    "\n",
    "Different algorithms\n",
    "\n",
    "Different hyperparameters\n",
    "\n",
    "Different feature subsets\n",
    "\n",
    "Different training subsets\n",
    "\n",
    "Dynamic Classifier Selection\n",
    "DCS: Choose best classifier per instance\n",
    "\n",
    "DES: Dynamic ensemble selection\n",
    "\n",
    "OLA (Overall Local Accuracy)\n",
    "\n",
    "LCA (Local Class Accuracy)\n",
    "\n",
    "Ensemble Pruning\n",
    "Why prune ensembles? (Redundancy, overfitting)\n",
    "\n",
    "Methods: Ranking-based, clustering-based, optimization-based\n",
    "\n",
    "How many models in an ensemble? (Law of diminishing returns)\n",
    "\n",
    "Online Ensemble Learning\n",
    "Online Bagging (Oza & Russell)\n",
    "\n",
    "Online Boosting\n",
    "\n",
    "Adapting to concept drift\n",
    "\n",
    "AdaBoost\n",
    "Prove that AdaBoost's training error decreases exponentially\n",
    "\n",
    "Derive the weight update rule from loss minimization perspective\n",
    "\n",
    "Why must weak learners have error < 0.5?\n",
    "\n",
    "Voting\n",
    "Prove that for independent classifiers with error p < 0.5, majority voting error → 0 as N → ∞\n",
    "\n",
    "What is the Condorcet Jury Theorem and its assumptions?\n",
    "\n",
    "Stacking\n",
    "Why does stacking with cross-validation prevent overfitting?\n",
    "\n",
    "How does stacking relate to Bayesian Model Averaging?\n",
    "\n",
    "General\n",
    "What is the bias-variance-covariance decomposition for ensembles?\n",
    "\n",
    "How does ambiguity decomposition explain ensemble success?\n",
    "\n",
    "\n",
    "AdaBoost\n",
    "How to handle imbalanced data in AdaBoost?\n",
    "\n",
    "What's the effect of increasing number of estimators?\n",
    "\n",
    "How to implement AdaBoost with custom weak learners?\n",
    "\n",
    "Stacking\n",
    "How to choose base models for stacking?\n",
    "\n",
    "What meta-learner works best?\n",
    "\n",
    "How to prevent overfitting in multi-layer stacking?\n",
    "\n",
    "How to handle different prediction types (probabilities vs. labels)?\n",
    "\n",
    "Voting\n",
    "How to determine optimal weights for weighted voting?\n",
    "\n",
    "Should you use calibrated probabilities for soft voting?\n",
    "\n",
    "How to handle models with different prediction speeds?\n",
    "\n",
    "\n",
    "Conceptual\n",
    "Explain AdaBoost to a non-technical person\n",
    "\n",
    "Why does boosting often outperform bagging?\n",
    "\n",
    "When would you choose stacking over a single complex model?\n",
    "\n",
    "What's the difference between bagging, boosting, and stacking?\n",
    "\n",
    "Technical\n",
    "How would you implement stacking without data leakage?\n",
    "\n",
    "What happens if all base models in voting make the same error?\n",
    "\n",
    "Why does AdaBoost use decision stumps as weak learners?\n",
    "\n",
    "How do you handle missing predictions in voting classifiers?\n",
    "\n",
    "Practical\n",
    "You have 5 models with accuracies: 0.85, 0.86, 0.84, 0.87, 0.83. Should you ensemble them?\n",
    "\n",
    "How would you combine a neural network and gradient boosting model?\n",
    "\n",
    "What metrics would you use to evaluate ensemble diversity?\n",
    "\n",
    "How to deploy an ensemble model in production efficiently?\n",
    "\n",
    "\n",
    "AdaBoost\n",
    "Face detection (Viola-Jones)\n",
    "\n",
    "Text classification\n",
    "\n",
    "Customer churn prediction\n",
    "\n",
    "Stacking\n",
    "Kaggle competitions (most winning solutions)\n",
    "\n",
    "Netflix Prize (blended models)\n",
    "\n",
    "Financial forecasting\n",
    "\n",
    "Voting\n",
    "Medical diagnosis systems\n",
    "\n",
    "Fraud detection\n",
    "\n",
    "Quality control systems\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
