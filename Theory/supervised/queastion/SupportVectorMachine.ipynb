{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c618d3",
   "metadata": {},
   "source": [
    "\n",
    "What is an SVM, and what problem does it solve?\n",
    "\n",
    "Explain the concept of a hyperplane in n-dimensional space.\n",
    "\n",
    "What are support vectors, and why are they important?\n",
    "\n",
    "What is the margin, and why do we want to maximize it?\n",
    "\n",
    "\n",
    "Formulate the hard-margin SVM optimization problem.\n",
    "\n",
    "What is the geometric margin vs. functional margin?\n",
    "\n",
    "\n",
    "\n",
    "What are the KKT conditions for SVM?\n",
    "\n",
    "\n",
    "Why do we need soft-margin SVM?\n",
    "\n",
    "Introduce slack variables ξᵢ.\n",
    "What does the C parameter control? (Trade-off between margin and misclassification)\n",
    "\n",
    "Derive the dual formulation of SVM.\n",
    "\n",
    "What is the Lagrangian dual problem?\n",
    "\n",
    "\n",
    "What is the kernel trick, and why is it revolutionary?\n",
    "\n",
    "\n",
    "kernel\n",
    "Polynomial kernel\n",
    "Sigmoid kernel\n",
    "RBF/Gaussian kernel\n",
    "How to choose the right kernel?\n",
    "\n",
    "How to choose the right kernel?\n",
    "\n",
    "Explain Mercer's Theorem and its importance for kernels.\n",
    "\n",
    "What is a Reproducing Kernel Hilbert Space (RKHS)?\n",
    "\n",
    "Why does SVM have a sparse solution? (Many αᵢ = 0)\n",
    "\n",
    "\n",
    "\n",
    "How does Support Vector Regression (SVR) work?\n",
    "\n",
    "What are ε-insensitive tubes?\n",
    "\n",
    "Formulate the SVR optimization problem.\n",
    "\n",
    "How does ε affect the solution?\n",
    "\n",
    "\n",
    "One-vs-Rest (OvR) approach\n",
    "\n",
    "One-vs-One (OvO) approach\n",
    "\n",
    "Direct multi-class SVM formulations\n",
    "\n",
    "Which approach is most commonly used?\n",
    "\n",
    "\n",
    "Scaling: Why is feature scaling crucial for SVM?\n",
    "\n",
    "Parameter tuning: Grid search for C, γ, kernel parameters\n",
    "\n",
    "Large datasets: Challenges and solutions (SMO algorithm)\n",
    "\n",
    "Memory requirements: Kernel matrix is O(n²)\n",
    "\n",
    "\n",
    "Sequential Minimal Optimization (SMO): How does it work?\n",
    "\n",
    "Coordinate descent methods\n",
    "\n",
    "LIBSVM and LIBLINEAR implementations\n",
    "\n",
    "GPU acceleration for SVM\n",
    "\n",
    "\n",
    "C (regularization parameter): Small vs. large values\n",
    "\n",
    "γ (RBF kernel parameter): Effect on decision boundary\n",
    "\n",
    "Degree (polynomial kernel): Controlling complexity\n",
    "\n",
    "ε (for SVR): Tolerance for errors\n",
    "\n",
    "Cross-validation strategies for SVM\n",
    "\n",
    "\n",
    "Advantages:\n",
    "Effective in high-dimensional spaces\n",
    "\n",
    "Memory efficient (uses only support vectors)\n",
    "\n",
    "Versatile (different kernels for different problems)\n",
    "\n",
    "Strong theoretical foundations\n",
    "\n",
    "Global optimum solution\n",
    "\n",
    "Disadvantages:\n",
    "Poor performance with noisy/overlapping classes\n",
    "\n",
    "Doesn't directly provide probability estimates\n",
    "\n",
    "Computationally expensive for large datasets\n",
    "\n",
    "Sensitive to kernel and parameter choices\n",
    "\n",
    "Hard to interpret with nonlinear kernels\n",
    "\n",
    "\n",
    "SVM vs. Logistic Regression for classification\n",
    "\n",
    "SVM vs. Neural Networks\n",
    "\n",
    "SVM vs. Decision Trees/Random Forests\n",
    "\n",
    "Linear SVM vs. Kernel SVM: When to use each?\n",
    "\n",
    "SVM vs. k-NN for small datasets\n",
    "\n",
    "For linear SVM: Feature weights indicate importance\n",
    "\n",
    "For kernel SVM: Harder to interpret\n",
    "\n",
    "Permutation importance for nonlinear SVMs\n",
    "\n",
    "Decision boundary visualization techniques\n",
    "\n",
    "\n",
    "Imbalanced classes: Class weighting in SVM\n",
    "\n",
    "Missing values: Preprocessing requirements\n",
    "\n",
    "Categorical features: Encoding strategies\n",
    "\n",
    "Outliers: Effect on SVM solution\n",
    "\n",
    "\n",
    "Why does maximizing margin lead to better generalization?\n",
    "\n",
    "Explain the VC dimension of SVM and its relation to generalization.\n",
    "\n",
    "What is the structural risk minimization principle in SVM?\n",
    "\n",
    "How does SVM relate to regularization theory?\n",
    "\n",
    "\n",
    "Why are SVMs called \"maximum margin classifiers\"?\n",
    "\n",
    "What happens when C → ∞ in soft-margin SVM?\n",
    "\n",
    "How does the RBF kernel parameter γ affect the decision boundary?\n",
    "\n",
    "Why can't we use the kernel trick with all algorithms?\n",
    "\n",
    "How would you explain SVM to a non-technical person?\n",
    "\n",
    "\n",
    "Derive the dual formulation from primal using Lagrangian.\n",
    "\n",
    "Prove that only support vectors have αᵢ > 0.\n",
    "\n",
    "Show that the margin width is 2/∣∣w∣∣ .\n",
    "\n",
    "Derive the decision function from dual variables.\n",
    "\n",
    "ν-SVM: Alternative parameterization\n",
    "\n",
    "Transductive SVM: Semi-supervised learning\n",
    "\n",
    "One-class SVM: Anomaly detection\n",
    "\n",
    "Multiple kernel learning (MKL)\n",
    "\n",
    "Structural SVM: For complex outputs\n",
    "\n",
    "\n",
    "Using scikit-learn: SVC, SVR, LinearSVC\n",
    "\n",
    "Choosing between LinearSVC and SVC(kernel='linear')\n",
    "\n",
    "Probability calibration with probability=True\n",
    "\n",
    "Handling large datasets with SGDClassifier (hinge loss)\n",
    "\n",
    "\n",
    "Text classification: High-dimensional sparse data\n",
    "\n",
    "Image recognition: With appropriate kernels\n",
    "\n",
    "Bioinformatics: Gene expression data\n",
    "\n",
    "Handwriting recognition\n",
    "\n",
    "Financial time series prediction\n",
    "\n",
    "\n",
    "Deep SVM: Combining with neural networks\n",
    "\n",
    "Random Fourier features for approximate kernel methods\n",
    "\n",
    "Quantum SVM formulations\n",
    "\n",
    "Incremental SVM for streaming data\n",
    "\n",
    "Forgetting to scale features\n",
    "\n",
    "Using RBF kernel without tuning γ\n",
    "\n",
    "Misinterpreting SVM outputs as probabilities\n",
    "\n",
    "Overfitting with too complex kernels\n",
    "\n",
    "Ignoring computational complexity for large n\n",
    "\n",
    "Caching kernel computations\n",
    "\n",
    "Approximate kernel methods for large datasets\n",
    "\n",
    "Model compression: Reducing number of support vectors\n",
    "\n",
    "Parallelization strategies"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
